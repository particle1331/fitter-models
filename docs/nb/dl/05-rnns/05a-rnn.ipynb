{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295b8542",
   "metadata": {
    "papermill": {
     "duration": 0.006471,
     "end_time": "2025-01-13T14:53:10.401527",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.395056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RNN  cell\n",
    "\n",
    "Previously, we described various language models where the conditional probability of token $\\boldsymbol{\\mathsf{x}}_t$ depends on a fixed context $\\boldsymbol{\\mathsf{x}}_{[t - \\tau: t-1]}.$ If we want to incorporate the possible effect of tokens earlier than the given context, we need to increase the context size $\\tau$. For the *n*-gram model, this would increase the parameters exponentially in $\\tau$. Using embeddings, the MLP network the number of parameters grows as $O(\\tau)$. Finally, using convolutions this decreases to $O(\\log \\tau).$\n",
    "Alternatively, instead of modeling the next token directly in terms of previous tokens, we can use a latent variable that, in principle, stores *all* previous information up to the previous time step:\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{\\mathsf x}_{t} \\mid \\boldsymbol{\\mathsf x}_{1}, \\ldots, \\boldsymbol{\\mathsf x}_{t-1}) \\approx p(\\boldsymbol{\\mathsf x}_{t} \\mid \\boldsymbol{\\mathsf h}_{t-1})\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\mathsf h}_{t-1}$ is a *hidden state* that stores information up to the time step $t - 1.$ The hidden state is updated based on the current input and the previous state: \n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mathsf h}_{t} = f(\\boldsymbol{\\mathsf x}_{t}, \\boldsymbol{\\mathsf h}_{t-1})\n",
    "$$\n",
    "\n",
    "so that $\\boldsymbol{\\mathsf h}_{t} = F(\\boldsymbol{\\mathsf x}_{1}, \\ldots, \\boldsymbol{\\mathsf x}_{t}, \\boldsymbol{\\mathsf h}_{0})$ for some $\\boldsymbol{\\mathsf h}_{0}$ where $F$ involves recursively applying $f$ (see {numref}`04-rnn`). For a sufficiently complex function $f$, the above latent variable model is not an approximation, since $\\boldsymbol{\\mathsf h}_{t}$ can simply store all $\\boldsymbol{\\mathsf x}_{1}, \\ldots, \\boldsymbol{\\mathsf x}_{t}$ it has observed so far. In our case, we use fully-connected layers whose complexity can be tuned with its width."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56109c",
   "metadata": {
    "papermill": {
     "duration": 0.005711,
     "end_time": "2025-01-13T14:53:10.415860",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.410149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "```{figure} ../../../img/nn/04-rnn.svg\n",
    "---\n",
    "width: 600px\n",
    "name: 04-rnn\n",
    "align: center\n",
    "---\n",
    "RNN unit (a) cyclic, and (b) unrolled RNN (essentially a deep MLP with shared weights).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3baf14",
   "metadata": {
    "papermill": {
     "duration": 0.002147,
     "end_time": "2025-01-13T14:53:10.423567",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.421420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**RNN cell.** Let each token be represented by vectors $\\boldsymbol{\\mathsf{x}}_t \\in \\mathbb{R}^{d}$ and let $\\boldsymbol{\\mathsf{h}}_0 = \\boldsymbol{0}.$ Then,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{\\mathsf{h}}_t &= \\tanh(\\boldsymbol{\\mathsf{x}}_t \\boldsymbol{\\mathsf{U}} + \\boldsymbol{\\mathsf{h}}_{t-1} \\boldsymbol{\\mathsf{W}} + \\boldsymbol{\\mathsf{b}}) \\\\\n",
    "\\boldsymbol{\\mathsf{y}}_t &= \\boldsymbol{\\mathsf{h}}_t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\mathsf{U}} \\in \\mathbb{R}^{d \\times h}$, $\\boldsymbol{\\mathsf{W}} \\in \\mathbb{R}^{h \\times h}$, and $\\boldsymbol{\\mathsf{b}} \\in \\mathbb{R}^{h}.$ Here $h$ is the dimensionality of the hidden state. For character-level inputs, $\\boldsymbol{\\mathsf{x}}_t$ can be a one-hot vector of length $|\\mathcal{V}|$ so that $\\boldsymbol{\\mathsf{U}}$ is $|\\mathcal{V}| \\times h$, also acting as the embedding matrix for the tokens[^1]. Finally, the state vector is also the **output** at each step, used by downstream layers of the network. The computation is illustrated in {numref}`04-simple-rnn`.\n",
    "\n",
    "[^1]: RNNs with input matrix $\\boldsymbol{\\mathsf{U}}$ of size $|\\mathcal{V}| \\times h$ does not work with large vocabularies. Vocabulary size $|\\mathcal{V}|$ can be very large (e.g., tens of thousands or more). If you directly use one-hot encoded vectors of size $|\\mathcal{V}|$, the cell input would be extremely high-dimensional and sparse. Instead of performing a full matrix multiplication, the embedding layer simply indexes into the embedding matrix to retrieve the corresponding dense vector for each word of size $d_\\text{emb}.$ Then, $\\boldsymbol{\\mathsf{U}}$ has shape $d_\\text{emb} \\times h.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2824f54a",
   "metadata": {
    "papermill": {
     "duration": 0.001828,
     "end_time": "2025-01-13T14:53:10.427645",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.425817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "```{figure} ../../../img/nn/04-simple-rnn.svg\n",
    "---\n",
    "width: 600px\n",
    "name: 04-simple-rnn\n",
    "align: center\n",
    "---\n",
    "Computational graph of an unrolled simple RNN. [Source](https://www.d2l.ai/chapter_recurrent-neural-networks/rnn.html)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a18fb5",
   "metadata": {
    "papermill": {
     "duration": 0.001805,
     "end_time": "2025-01-13T14:53:10.431331",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.429526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Remark.** RNNs use the same parameters at each time step, i.e. it is assumed that the dynamics is *stationary*. Practically, this means that the parameter count does not grow as the sequence length increases, and that the parameters have to time index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cfb63",
   "metadata": {
    "papermill": {
     "duration": 0.002051,
     "end_time": "2025-01-13T14:53:10.435814",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.433763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9c08e",
   "metadata": {
    "papermill": {
     "duration": 0.001874,
     "end_time": "2025-01-13T14:53:10.442346",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.440472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, we implement the recurrent layer. To implement batch computation, an input $\\boldsymbol{\\mathsf{X}}$ has shape $(T, B, d).$ That is, a batch of $B$ sequences of length $T$, consisting of vectors in $\\mathbb{R}^{d}.$ Elements of a batch are computed independently, ideally in parallel. For example, $\\boldsymbol{\\mathsf{X}}_{[0, :, :]}$ consist of a batch of all vectors at $t = 0.$ Similarly, $\\boldsymbol{\\mathsf{X}}_{[:, 0, :]}$ is one instance of a sequence of vectors. At each step, the layer returns the state vector of shape $(B, h).$ These are stacked to get a tensor of shape $(T, B,h)$ consistent with the input. RNN cell computation can be written as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54486614",
   "metadata": {
    "papermill": {
     "duration": 0.002189,
     "end_time": "2025-01-13T14:53:10.446697",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.444508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "outs = []\n",
    "for t in range(T):\n",
    "    h = torch.tanh(x[t] @ self.U + h @ self.W + self.b)\n",
    "    outs.append(h)\n",
    "```\n",
    "\n",
    "Here the state `h`is updated at each step, and the output vector is also set to `h` at each step. The initialization of the state vector is not shown, but we typically set it to zero when not specified.\n",
    "This leads us to the required methods in the base class below. But first, let us define the expected \"shape\" of an RNN unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfebb858",
   "metadata": {
    "papermill": {
     "duration": 0.001768,
     "end_time": "2025-01-13T14:53:10.451016",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.449248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Base RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34208ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:53:10.457398Z",
     "iopub.status.busy": "2025-01-13T14:53:10.457084Z",
     "iopub.status.idle": "2025-01-13T14:53:10.463410Z",
     "shell.execute_reply": "2025-01-13T14:53:10.463095Z"
    },
    "papermill": {
     "duration": 0.010339,
     "end_time": "2025-01-13T14:53:10.464473",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.454134",
     "status": "completed"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from chapter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532447b",
   "metadata": {
    "papermill": {
     "duration": 0.002235,
     "end_time": "2025-01-13T14:53:10.468770",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.466535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A *recurrent unit* is any function that iteratively updates a state based on new sequence input, it may haver other layers for downstream processing at each time step, so we also return an output tensor. We set the following guidelines:\n",
    "\n",
    "1. A recurrent unit must have `(inputs_dim, hidden_dim, **kwargs)` as arguments.\n",
    "2. It's forward signature is `(x, state=None)` where `x` is \"sequence first\", i.e. $(T, B, d)$.\n",
    "3. It's forward return format is `outs, state` where `state` has the expected format as input for the forward function and `outs` has shape $(T, B, h)$.\n",
    "\n",
    "The parameter `(d, h)` for an RNN can be read off as transforming the each sequence element from $\\mathbb{R}^d$ to $\\mathbb{R}^h.$ Next, an implementation with expected inputs $(T, B, d)$ is already linear layer friendly. This can be interpreted as processing an entire batch at each time step, instead of entire sequences per batch. Hence, we choose this over the more intuitive \"batch first\" shape $(B, T, d)$. \n",
    "\n",
    "Finally, while the output has to be of shape $(T, B, h)$, the `state` is more arbitrary. For example, it can be a tuple of tensors `(h, c)`. As such, we can call the unit with either `(x)` or `(x, state=(h0, c0))`. This latter is useful for setting up a warmup state, or continuing inference with another input sequence. The only constraint is that the states are consistently formatted in all parts of a specific implementation. For example, if `state` is the current output state, then the unit can be called next with `(x, state=state)` without errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb68a2f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:53:10.474129Z",
     "iopub.status.busy": "2025-01-13T14:53:10.473956Z",
     "iopub.status.idle": "2025-01-13T14:53:11.191152Z",
     "shell.execute_reply": "2025-01-13T14:53:11.190829Z"
    },
    "papermill": {
     "duration": 0.72199,
     "end_time": "2025-01-13T14:53:11.192707",
     "exception": false,
     "start_time": "2025-01-13T14:53:10.470717",
     "status": "completed"
    },
    "tags": [
     "remove-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">random</span>\n",
       "\n",
       "<span class=\"n\">RANDOM_SEED</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n",
       "<span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">RANDOM_SEED</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">RANDOM_SEED</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">manual_seed</span><span class=\"p\">(</span><span class=\"n\">RANDOM_SEED</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">MPS</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">backends</span><span class=\"o\">.</span><span class=\"n\">mps</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">CUDA</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">DEVICE</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s2\">&quot;cuda:0&quot;</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">CUDA</span> <span class=\"k\">else</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s2\">&quot;mps&quot;</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">MPS</span> <span class=\"k\">else</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s2\">&quot;cpu&quot;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{nn} \\PY{k}{as} \\PY{n+nn}{nn}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{random}\n",
       "\n",
       "\\PY{n}{RANDOM\\PYZus{}SEED} \\PY{o}{=} \\PY{l+m+mi}{0}\n",
       "\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{RANDOM\\PYZus{}SEED}\\PY{p}{)}\n",
       "\\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{RANDOM\\PYZus{}SEED}\\PY{p}{)}\n",
       "\\PY{n}{torch}\\PY{o}{.}\\PY{n}{manual\\PYZus{}seed}\\PY{p}{(}\\PY{n}{RANDOM\\PYZus{}SEED}\\PY{p}{)}\n",
       "\\PY{n}{MPS} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{backends}\\PY{o}{.}\\PY{n}{mps}\\PY{o}{.}\\PY{n}{is\\PYZus{}available}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{CUDA} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{cuda}\\PY{o}{.}\\PY{n}{is\\PYZus{}available}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{DEVICE} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{device}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{cuda:0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)} \\PY{k}{if} \\PY{n}{CUDA} \\PY{k}{else} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{device}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{mps}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)} \\PY{k}{if} \\PY{n}{MPS} \\PY{k}{else} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{device}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{cpu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import torch\n",
       "import torch.nn as nn\n",
       "import numpy as np\n",
       "import random\n",
       "\n",
       "RANDOM_SEED = 0\n",
       "random.seed(RANDOM_SEED)\n",
       "np.random.seed(RANDOM_SEED)\n",
       "torch.manual_seed(RANDOM_SEED)\n",
       "MPS = torch.backends.mps.is_available()\n",
       "CUDA = torch.cuda.is_available()\n",
       "DEVICE = torch.device(\"cuda:0\") if CUDA else torch.device(\"mps\") if MPS else torch.device(\"cpu\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%save\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "MPS = torch.backends.mps.is_available()\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda:0\") if CUDA else torch.device(\"mps\") if MPS else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3372eb93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:53:11.197429Z",
     "iopub.status.busy": "2025-01-13T14:53:11.197206Z",
     "iopub.status.idle": "2025-01-13T14:53:11.202288Z",
     "shell.execute_reply": "2025-01-13T14:53:11.202051Z"
    },
    "papermill": {
     "duration": 0.008041,
     "end_time": "2025-01-13T14:53:11.203137",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.195096",
     "status": "completed"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">RNNBase</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n",
       "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;Base class for recurrent units, e.g. RNN, LSTM, GRU, etc.&quot;&quot;&quot;</span>\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">inputs_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">hidden_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">hidden_dim</span> <span class=\"o\">=</span> <span class=\"n\">hidden_dim</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">inputs_dim</span> <span class=\"o\">=</span> <span class=\"n\">inputs_dim</span>\n",
       "        \n",
       "    <span class=\"k\">def</span> <span class=\"nf\">init_state</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">NotImplementedError</span>\n",
       "    \n",
       "    <span class=\"k\">def</span> <span class=\"nf\">compute</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">NotImplementedError</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">init_state</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">state</span> <span class=\"ow\">is</span> <span class=\"kc\">None</span> <span class=\"k\">else</span> <span class=\"n\">state</span>\n",
       "        <span class=\"n\">outs</span><span class=\"p\">,</span> <span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">outs</span><span class=\"p\">,</span> <span class=\"n\">state</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{class} \\PY{n+nc}{RNNBase}\\PY{p}{(}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module}\\PY{p}{)}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}Base class for recurrent units, e.g. RNN, LSTM, GRU, etc.\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{inputs\\PYZus{}dim}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{,} \\PY{n}{hidden\\PYZus{}dim}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{hidden\\PYZus{}dim} \\PY{o}{=} \\PY{n}{hidden\\PYZus{}dim}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{inputs\\PYZus{}dim} \\PY{o}{=} \\PY{n}{inputs\\PYZus{}dim}\n",
       "        \n",
       "    \\PY{k}{def} \\PY{n+nf}{init\\PYZus{}state}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{NotImplementedError}\n",
       "    \n",
       "    \\PY{k}{def} \\PY{n+nf}{compute}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{,} \\PY{n}{state}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{NotImplementedError}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{forward}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{,} \\PY{n}{state}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{state} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{init\\PYZus{}state}\\PY{p}{(}\\PY{n}{x}\\PY{p}{)} \\PY{k}{if} \\PY{n}{state} \\PY{o+ow}{is} \\PY{k+kc}{None} \\PY{k}{else} \\PY{n}{state}\n",
       "        \\PY{n}{outs}\\PY{p}{,} \\PY{n}{state} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{compute}\\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{state}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{outs}\\PY{p}{,} \\PY{n}{state}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "class RNNBase(nn.Module):\n",
       "    \"\"\"Base class for recurrent units, e.g. RNN, LSTM, GRU, etc.\"\"\"\n",
       "    def __init__(self, inputs_dim: int, hidden_dim: int):\n",
       "        super().__init__()\n",
       "        self.hidden_dim = hidden_dim\n",
       "        self.inputs_dim = inputs_dim\n",
       "        \n",
       "    def init_state(self, x):\n",
       "        raise NotImplementedError\n",
       "    \n",
       "    def compute(self, x, state):\n",
       "        raise NotImplementedError\n",
       "\n",
       "    def forward(self, x, state=None):\n",
       "        state = self.init_state(x) if state is None else state\n",
       "        outs, state = self.compute(x, state)\n",
       "        return outs, state"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%save\n",
    "class RNNBase(nn.Module):\n",
    "    \"\"\"Base class for recurrent units, e.g. RNN, LSTM, GRU, etc.\"\"\"\n",
    "    def __init__(self, inputs_dim: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.inputs_dim = inputs_dim\n",
    "        \n",
    "    def init_state(self, x):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def compute(self, x, state):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        state = self.init_state(x) if state is None else state\n",
    "        outs, state = self.compute(x, state)\n",
    "        return outs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f15da6",
   "metadata": {
    "papermill": {
     "duration": 0.001614,
     "end_time": "2025-01-13T14:53:11.206446",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.204832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Implementing the basic RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e584caa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:53:11.210273Z",
     "iopub.status.busy": "2025-01-13T14:53:11.210133Z",
     "iopub.status.idle": "2025-01-13T14:53:11.216872Z",
     "shell.execute_reply": "2025-01-13T14:53:11.216639Z"
    },
    "papermill": {
     "duration": 0.00968,
     "end_time": "2025-01-13T14:53:11.217725",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.208045",
     "status": "completed"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">RNN</span><span class=\"p\">(</span><span class=\"n\">RNNBase</span><span class=\"p\">):</span>\n",
       "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;Simple RNN unit.&quot;&quot;&quot;</span>\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">inputs_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">hidden_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"n\">inputs_dim</span><span class=\"p\">,</span> <span class=\"n\">hidden_dim</span><span class=\"p\">)</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">U</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Parameter</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">inputs_dim</span><span class=\"p\">,</span> <span class=\"n\">hidden_dim</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">sqrt</span><span class=\"p\">(</span><span class=\"n\">inputs_dim</span><span class=\"p\">))</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">W</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Parameter</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">hidden_dim</span><span class=\"p\">,</span> <span class=\"n\">hidden_dim</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">sqrt</span><span class=\"p\">(</span><span class=\"n\">hidden_dim</span><span class=\"p\">))</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Parameter</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">hidden_dim</span><span class=\"p\">))</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">init_state</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">B</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
       "        <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">hidden_dim</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">h</span>\n",
       "    \n",
       "    <span class=\"k\">def</span> <span class=\"nf\">compute</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">state</span>\n",
       "        <span class=\"n\">T</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
       "        <span class=\"n\">outs</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">t</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">T</span><span class=\"p\">):</span>\n",
       "            <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tanh</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"n\">t</span><span class=\"p\">]</span> <span class=\"o\">@</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">U</span> <span class=\"o\">+</span> <span class=\"n\">h</span> <span class=\"o\">@</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">W</span> <span class=\"o\">+</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">b</span><span class=\"p\">)</span>\n",
       "            <span class=\"n\">outs</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">h</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">stack</span><span class=\"p\">(</span><span class=\"n\">outs</span><span class=\"p\">),</span> <span class=\"n\">h</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{class} \\PY{n+nc}{RNN}\\PY{p}{(}\\PY{n}{RNNBase}\\PY{p}{)}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}Simple RNN unit.\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{inputs\\PYZus{}dim}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{,} \\PY{n}{hidden\\PYZus{}dim}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n}{inputs\\PYZus{}dim}\\PY{p}{,} \\PY{n}{hidden\\PYZus{}dim}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{U} \\PY{o}{=} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Parameter}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{randn}\\PY{p}{(}\\PY{n}{inputs\\PYZus{}dim}\\PY{p}{,} \\PY{n}{hidden\\PYZus{}dim}\\PY{p}{)} \\PY{o}{/} \\PY{n}{np}\\PY{o}{.}\\PY{n}{sqrt}\\PY{p}{(}\\PY{n}{inputs\\PYZus{}dim}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{W} \\PY{o}{=} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Parameter}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{randn}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}dim}\\PY{p}{,} \\PY{n}{hidden\\PYZus{}dim}\\PY{p}{)} \\PY{o}{/} \\PY{n}{np}\\PY{o}{.}\\PY{n}{sqrt}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}dim}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{b} \\PY{o}{=} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Parameter}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{zeros}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}dim}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{init\\PYZus{}state}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{B} \\PY{o}{=} \\PY{n}{x}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\n",
       "        \\PY{n}{h} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{zeros}\\PY{p}{(}\\PY{n}{B}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{hidden\\PYZus{}dim}\\PY{p}{,} \\PY{n}{device}\\PY{o}{=}\\PY{n}{x}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{h}\n",
       "    \n",
       "    \\PY{k}{def} \\PY{n+nf}{compute}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{,} \\PY{n}{state}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{h} \\PY{o}{=} \\PY{n}{state}\n",
       "        \\PY{n}{T} \\PY{o}{=} \\PY{n}{x}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n",
       "        \\PY{n}{outs} \\PY{o}{=} \\PY{p}{[}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{t} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n}{T}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{n}{h} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{tanh}\\PY{p}{(}\\PY{n}{x}\\PY{p}{[}\\PY{n}{t}\\PY{p}{]} \\PY{o}{@} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{U} \\PY{o}{+} \\PY{n}{h} \\PY{o}{@} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{W} \\PY{o}{+} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{b}\\PY{p}{)}\n",
       "            \\PY{n}{outs}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n}{h}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{stack}\\PY{p}{(}\\PY{n}{outs}\\PY{p}{)}\\PY{p}{,} \\PY{n}{h}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "class RNN(RNNBase):\n",
       "    \"\"\"Simple RNN unit.\"\"\"\n",
       "    def __init__(self, inputs_dim: int, hidden_dim: int):\n",
       "        super().__init__(inputs_dim, hidden_dim)\n",
       "        self.U = nn.Parameter(torch.randn(inputs_dim, hidden_dim) / np.sqrt(inputs_dim))\n",
       "        self.W = nn.Parameter(torch.randn(hidden_dim, hidden_dim) / np.sqrt(hidden_dim))\n",
       "        self.b = nn.Parameter(torch.zeros(hidden_dim))\n",
       "\n",
       "    def init_state(self, x):\n",
       "        B = x.shape[1]\n",
       "        h = torch.zeros(B, self.hidden_dim, device=x.device)\n",
       "        return h\n",
       "    \n",
       "    def compute(self, x, state):\n",
       "        h = state\n",
       "        T = x.shape[0]\n",
       "        outs = []\n",
       "        for t in range(T):\n",
       "            h = torch.tanh(x[t] @ self.U + h @ self.W + self.b)\n",
       "            outs.append(h)\n",
       "        return torch.stack(outs), h"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%save\n",
    "class RNN(RNNBase):\n",
    "    \"\"\"Simple RNN unit.\"\"\"\n",
    "    def __init__(self, inputs_dim: int, hidden_dim: int):\n",
    "        super().__init__(inputs_dim, hidden_dim)\n",
    "        self.U = nn.Parameter(torch.randn(inputs_dim, hidden_dim) / np.sqrt(inputs_dim))\n",
    "        self.W = nn.Parameter(torch.randn(hidden_dim, hidden_dim) / np.sqrt(hidden_dim))\n",
    "        self.b = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "    def init_state(self, x):\n",
    "        B = x.shape[1]\n",
    "        h = torch.zeros(B, self.hidden_dim, device=x.device)\n",
    "        return h\n",
    "    \n",
    "    def compute(self, x, state):\n",
    "        h = state\n",
    "        T = x.shape[0]\n",
    "        outs = []\n",
    "        for t in range(T):\n",
    "            h = torch.tanh(x[t] @ self.U + h @ self.W + self.b)\n",
    "            outs.append(h)\n",
    "        return torch.stack(outs), h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ccc77",
   "metadata": {
    "papermill": {
     "duration": 0.001685,
     "end_time": "2025-01-13T14:53:11.221201",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.219516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Remark.** It's important to note that our RNN does not store state outside of forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca2d3d",
   "metadata": {
    "papermill": {
     "duration": 0.001683,
     "end_time": "2025-01-13T14:53:11.225150",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.223467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Shapes test, i.e. $(T, B, d)$ to $(T, B, h)$ for a network with params $(d, h)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73338dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:53:11.229244Z",
     "iopub.status.busy": "2025-01-13T14:53:11.229046Z",
     "iopub.status.idle": "2025-01-13T14:53:11.232779Z",
     "shell.execute_reply": "2025-01-13T14:53:11.232535Z"
    },
    "papermill": {
     "duration": 0.006823,
     "end_time": "2025-01-13T14:53:11.233680",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.226857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "B, T, d, h = 32, 10, 30, 5\n",
    "x = torch.randn(T, B, d)\n",
    "rnn = RNN(d, h)\n",
    "outs, state = rnn(x)\n",
    "assert outs.shape == (T, B, h)\n",
    "assert state.shape == (B, h)\n",
    "assert torch.abs(outs[-1] - state).max() < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a35ae4",
   "metadata": {
    "papermill": {
     "duration": 0.001715,
     "end_time": "2025-01-13T14:53:11.237231",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.235516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "**Remark.** The PyTorch RNN module has a similar API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fdc8a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:53:11.241216Z",
     "iopub.status.busy": "2025-01-13T14:53:11.241087Z",
     "iopub.status.idle": "2025-01-13T14:53:11.244312Z",
     "shell.execute_reply": "2025-01-13T14:53:11.244009Z"
    },
    "papermill": {
     "duration": 0.006164,
     "end_time": "2025-01-13T14:53:11.245092",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.238928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "B, T, d, h = 32, 10, 30, 5\n",
    "rnn_torch = nn.RNN(d, h)\n",
    "outs, state = rnn_torch(x)\n",
    "assert outs.shape == (T, B, h)\n",
    "assert state.shape == (1, B, h)\n",
    "assert torch.abs(outs[-1] - state).max() < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6488d",
   "metadata": {
    "papermill": {
     "duration": 0.00173,
     "end_time": "2025-01-13T14:53:11.248673",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.246943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5842cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:53:11.252567Z",
     "iopub.status.busy": "2025-01-13T14:53:11.252471Z",
     "iopub.status.idle": "2025-01-13T14:53:11.255418Z",
     "shell.execute_reply": "2025-01-13T14:53:11.255185Z"
    },
    "papermill": {
     "duration": 0.005863,
     "end_time": "2025-01-13T14:53:11.256255",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.250392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for name, p in rnn.named_parameters():\n",
    "    if name == \"b\":\n",
    "        p.data.fill_(0.0)\n",
    "    else:\n",
    "        p.data.fill_(1.0)\n",
    "\n",
    "for name, p in rnn_torch.named_parameters():\n",
    "    if \"bias\" in name:\n",
    "        p.data.fill_(0.0)\n",
    "    else:\n",
    "        p.data.fill_(1.0)\n",
    "\n",
    "error = torch.abs(rnn(x)[0] - rnn_torch(x)[0]).max()\n",
    "print(error)\n",
    "assert error < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c64fd4",
   "metadata": {
    "papermill": {
     "duration": 0.001727,
     "end_time": "2025-01-13T14:53:11.259865",
     "exception": false,
     "start_time": "2025-01-13T14:53:11.258138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.021179,
   "end_time": "2025-01-13T14:53:11.578889",
   "environment_variables": {},
   "exception": null,
   "input_path": "05a-rnn.ipynb",
   "output_path": "05a-rnn.ipynb",
   "parameters": {},
   "start_time": "2025-01-13T14:53:09.557710",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}